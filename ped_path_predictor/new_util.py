import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np


def load_data(file, n_obs, n_pred, absolute=False):
    with open(file, "rb") as f:
        raw = np.load(f, allow_pickle=True).astype("float32")

    window = raw.shape[1] - n_obs - n_pred

    observed_data, predict_data = [], []
    for k in range(0, window, 20):
        observed = raw[:, k : n_obs + k, :]
        pred = raw[:, k + n_obs : n_pred + n_obs + k, 0:2]

        observed_data.append(observed)
        predict_data.append(pred)

    observed_data = np.concatenate(observed_data, axis=0)
    predict_data = np.concatenate(predict_data, axis=0)

    if not absolute:
        # make output relative to the last observed frame
        i_t = observed_data[:, n_obs - 1, 0:2]
        i_t = np.expand_dims(i_t, axis=1)
        i_t = np.repeat(i_t, n_pred, axis=1)
        predict_data = predict_data - i_t

    return torch.tensor(observed_data), torch.tensor(predict_data)


def get_dat_sets(paths: list, n_obs, n_pred, absolute=False):
    assert len(paths) > 0, "No paths provided"

    train, test = [], []

    for path in paths:
        x, y = load_data(path, n_obs, n_pred, absolute=absolute)
        train.append(x)
        test.append(y)

    return np.concatenate(train), np.concatenate(test)


class MultiDataset(Dataset):
    def __init__(self, paths_p1, paths_p2, paths_car, n_obs, n_pred, absolute=False) -> None:
        super().__init__()

        input_p1, output_p1 = get_dat_sets(paths_p1, n_obs, n_pred, absolute=absolute)
        input_p2, output_p2 = get_dat_sets(paths_p2, n_obs, n_pred, absolute=absolute)
        input_car, output_car = get_dat_sets(paths_car, n_obs, n_pred, absolute=absolute)

        self.x = np.concatenate([input_p1, input_p2, input_car], axis=-1, dtype=np.float32)
        self.y = np.concatenate([output_p1, output_p2, output_car], axis=-1, dtype=np.float32)

    def __len__(self):
        return len(self.x)

    def __getitem__(self, idx):
        return self.x[idx], self.y[idx]


class IctsDataset(Dataset):
    def __init__(self, path_int, path_non_int, path_int_car, path_non_int_car, n_obs, n_pred, absolute=False) -> None:
        super().__init__()

        input_ped, output_ped = get_dat_sets([path_int, path_non_int], n_obs, n_pred, absolute=absolute)
        input_car, output_car = get_dat_sets([path_int_car, path_non_int_car], n_obs, n_pred, absolute=absolute)

        self.x = np.concatenate([input_ped, input_car], axis=-1, dtype=np.float32)
        self.y = output_ped

    def __len__(self):
        return len(self.x)

    def __getitem__(self, idx):
        return self.x[idx], self.y[idx]


class IctsDatasetDynGroup(Dataset):
    def __init__(self, path_int, path_non_int, path_int_car, path_non_int_car, n_obs, n_pred, absolute=False) -> None:
        super().__init__()

        input_ped, output_ped = get_dat_sets([path_int, path_non_int], n_obs, n_pred, absolute=absolute)
        input_car, output_car = get_dat_sets([path_int_car, path_non_int_car], n_obs, n_pred, absolute=absolute)

        self.x = np.concatenate([input_ped, input_car], axis=-1, dtype=np.float32)
        self.y = np.concatenate([output_ped, output_car], axis=-1, dtype=np.float32)

    def __len__(self):
        return len(self.x)

    def __getitem__(self, idx):
        return self.x[idx], self.y[idx]


class IctsTrajPed(Dataset):
    def __init__(self, path_int, path_non_int, path_int_car, path_non_int_car, n_obs, n_pred, absolute=False) -> None:
        super().__init__()

        input_ped, output_ped = get_dat_sets([path_int, path_non_int], n_obs, n_pred, absolute=absolute)
        input_car, output_car = get_dat_sets([path_int_car, path_non_int_car], n_obs, n_pred, absolute=absolute)

        self.x = np.concatenate([input_ped], axis=-1, dtype=np.float32)
        self.y = np.concatenate([output_ped], axis=-1, dtype=np.float32)

    def __len__(self):
        return len(self.x)

    def __getitem__(self, idx):
        return self.x[idx], self.y[idx]


class IctsTrajCar(Dataset):
    def __init__(self, path_int, path_non_int, path_int_car, path_non_int_car, n_obs, n_pred, absolute=False) -> None:
        super().__init__()

        input_ped, output_ped = get_dat_sets([path_int, path_non_int], n_obs, n_pred, absolute=absolute)
        input_car, output_car = get_dat_sets([path_int_car, path_non_int_car], n_obs, n_pred, absolute=absolute)

        self.x = np.concatenate([input_car], axis=-1, dtype=np.float32)
        self.y = np.concatenate([output_car], axis=-1, dtype=np.float32)

    def __len__(self):
        return len(self.x)

    def __getitem__(self, idx):
        return self.x[idx], self.y[idx]


def getDataloadersDynGroup(
    path_int, path_non_int, path_int_car, path_non_int_car, n_obs, n_pred, batch_size=64, absolute=False
):
    dataset = IctsDatasetDynGroup(
        path_int, path_non_int, path_int_car, path_non_int_car, n_obs, n_pred, absolute=absolute
    )

    train_size = int(0.7 * len(dataset))
    test_size = len(dataset) - train_size
    train_dataset, test_dataset = torch.utils.data.random_split(
        dataset, [train_size, test_size], generator=torch.Generator().manual_seed(42)
    )

    test_dataset, val_dataset = torch.utils.data.random_split(
        test_dataset,
        [int(0.5 * len(test_dataset)), len(test_dataset) - int(0.5 * len(test_dataset))],
        generator=torch.Generator().manual_seed(42),
    )

    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)

    return train_dataloader, test_dataloader, val_dataloader


def getDataloadersTrajectron(
    path_int, path_non_int, path_int_car, path_non_int_car, n_obs, n_pred, batch_size=64, absolute=False
):
    dataset_ped = IctsTrajPed(path_int, path_non_int, path_int_car, path_non_int_car, n_obs, n_pred, absolute=absolute)

    train_size = int(0.7 * len(dataset_ped))
    test_size = len(dataset_ped) - train_size
    train_dataset, test_dataset = torch.utils.data.random_split(
        dataset_ped, [train_size, test_size], generator=torch.Generator().manual_seed(42)
    )

    test_dataset, val_dataset = torch.utils.data.random_split(
        test_dataset,
        [int(0.5 * len(test_dataset)), len(test_dataset) - int(0.5 * len(test_dataset))],
        generator=torch.Generator().manual_seed(42),
    )

    train_dataloader_ped = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
    test_dataloader_ped = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
    val_dataloader_ped = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)

    dataset_car = IctsTrajCar(path_int, path_non_int, path_int_car, path_non_int_car, n_obs, n_pred, absolute=absolute)

    train_size = int(0.7 * len(dataset_car))
    test_size = len(dataset_car) - train_size
    train_dataset, test_dataset = torch.utils.data.random_split(
        dataset_car, [train_size, test_size], generator=torch.Generator().manual_seed(42)
    )

    test_dataset, val_dataset = torch.utils.data.random_split(
        test_dataset,
        [int(0.5 * len(test_dataset)), len(test_dataset) - int(0.5 * len(test_dataset))],
        generator=torch.Generator().manual_seed(42),
    )

    train_dataloader_car = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
    test_dataloader_car = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
    val_dataloader_car = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)

    return (
        train_dataloader_ped,
        test_dataloader_ped,
        val_dataloader_ped,
        train_dataloader_car,
        test_dataloader_car,
        val_dataloader_car,
    )


def getDataloaders(
    path_int, path_non_int, path_int_car, path_non_int_car, n_obs, n_pred, batch_size=64, absolute=False
):

    dataset = IctsDataset(path_int, path_non_int, path_int_car, path_non_int_car, n_obs, n_pred, absolute=absolute)

    train_size = int(0.7 * len(dataset))
    test_size = len(dataset) - train_size
    train_dataset, test_dataset = torch.utils.data.random_split(
        dataset, [train_size, test_size], generator=torch.Generator().manual_seed(42)
    )

    test_dataset, val_dataset = torch.utils.data.random_split(
        test_dataset,
        [int(0.5 * len(test_dataset)), len(test_dataset) - int(0.5 * len(test_dataset))],
        generator=torch.Generator().manual_seed(42),
    )

    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)

    return train_dataloader, test_dataloader, val_dataloader


def getDataloadersMulti(paths_p1, paths_p2, paths_car, n_obs, n_pred, batch_size=64, absolute=False):

    dataset = MultiDataset(paths_p1, paths_p2, paths_car, n_obs, n_pred, absolute=absolute)

    train_size = int(0.7 * len(dataset))
    test_size = len(dataset) - train_size
    train_dataset, test_dataset = torch.utils.data.random_split(
        dataset, [train_size, test_size], generator=torch.Generator().manual_seed(42)
    )

    test_dataset, val_dataset = torch.utils.data.random_split(
        test_dataset,
        [int(0.5 * len(test_dataset)), len(test_dataset) - int(0.5 * len(test_dataset))],
        generator=torch.Generator().manual_seed(42),
    )

    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=True)
    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=True)
    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=True)

    return train_dataloader, test_dataloader, val_dataloader


class SingleIctsDataset(Dataset):
    def __init__(self, path_ped, path_car, n_obs, n_pred) -> None:
        super().__init__()

        input_ped, output_ped = get_dat_sets([path_ped], n_obs, n_pred)
        input_cat, output_car = get_dat_sets([path_car], n_obs, n_pred)

        self.x = np.concatenate([input_ped, input_cat], axis=-1, dtype=np.float32)
        self.y = output_ped

    def __len__(self):
        return len(self.x)

    def __getitem__(self, idx):
        return self.x[idx], self.y[idx]


class SingleIctsDatasetDynGroup(Dataset):
    def __init__(self, path_ped, path_car, n_obs, n_pred) -> None:
        super().__init__()

        input_ped, output_ped = get_dat_sets([path_ped], n_obs, n_pred)
        input_cat, output_car = get_dat_sets([path_car], n_obs, n_pred)

        self.x = np.concatenate([input_ped, input_cat], axis=-1, dtype=np.float32)
        self.y = np.concatenate([output_ped, output_car], axis=-1, dtype=np.float32)

    def __len__(self):
        return len(self.x)

    def __getitem__(self, idx):
        return self.x[idx], self.y[idx]


def singleDatasets(path_tuple, n_obs, n_pred, batch_size=64):
    dataset = SingleIctsDataset(path_tuple[0], path_tuple[1], n_obs, n_pred)
    return DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)


def singleDatasetsDynGroup(path_tuple, n_obs, n_pred, batch_size=64):
    dataset = SingleIctsDatasetDynGroup(path_tuple[0], path_tuple[1], n_obs, n_pred)
    return DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)
